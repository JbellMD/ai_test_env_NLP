{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Demo\n",
    "\n",
    "This notebook demonstrates the text classification capabilities of the NLP toolkit, including:\n",
    "- Loading and preprocessing data\n",
    "- Training a transformer-based classifier\n",
    "- Evaluating model performance\n",
    "- Visualizing results\n",
    "- Making predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup path to allow importing from the src directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import toolkit modules\n",
    "from src.data.preprocessing import TextPreprocessor\n",
    "from src.data.data_loader import get_text_classification_loader\n",
    "from src.models.classifier import TransformerClassifier\n",
    "from src.training.metrics import classification_report\n",
    "from src.utils.visualization import plot_confusion_matrix, plot_classification_metrics, plot_training_history\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "TASK = \"classification\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"  # Smaller model for faster execution\n",
    "DATASET_NAME = \"imdb\"  # Movie reviews sentiment dataset\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1  # Using just 1 epoch for demonstration purposes\n",
    "\n",
    "# Output directory for model and results\n",
    "OUTPUT_DIR = os.path.join(project_root, \"models\", \"demo_classifier\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Create dataset loader\n",
    "dataset_loader = get_text_classification_loader(\n",
    "    tokenizer=tokenizer,\n",
    "    preprocessor=preprocessor,\n",
    "    max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "dataset = dataset_loader.load_huggingface_dataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    text_column=\"text\",\n",
    "    label_column=\"label\"\n",
    ")\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Number of splits: {len(dataset.keys())}\")\n",
    "for split in dataset.keys():\n",
    "    print(f\"  {split}: {len(dataset[split])} examples\")\n",
    "\n",
    "# Show example data\n",
    "print(\"\\nExample data:\")\n",
    "for i, example in enumerate(dataset[\"train\"][:3]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Text: {example['text'][:100]}...\")\n",
    "    print(f\"  Label: {example['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess the dataset\n",
    "preprocessed_dataset = dataset_loader.preprocess_dataset(dataset)\n",
    "\n",
    "# Create PyTorch DataLoaders\n",
    "dataloaders = dataset_loader.create_torch_dataloaders(\n",
    "    preprocessed_dataset,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Extract train and validation dataloaders\n",
    "train_dataloader = dataloaders[\"train\"]\n",
    "val_dataloader = dataloaders[\"test\"]\n",
    "\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize classifier\n",
    "classifier = TransformerClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_labels=2  # Binary classification for IMDB\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Number of parameters: {classifier.get_model_size():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "training_history = classifier.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=0,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_best=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize training history\n",
    "plot_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "eval_results = classifier.evaluate(val_dataloader)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(f\"  Loss: {eval_results['loss']:.4f}\")\n",
    "print(f\"  Accuracy: {eval_results['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {eval_results['precision']:.4f}\")\n",
    "print(f\"  Recall: {eval_results['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {eval_results['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute predictions and true labels\n",
    "import torch\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probas = []\n",
    "\n",
    "device = classifier.device\n",
    "model = classifier.model\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        probas = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        all_labels.extend(labels)\n",
    "        all_probas.extend(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot confusion matrix\n",
    "class_names = [\"Negative\", \"Positive\"]\n",
    "plot_confusion_matrix(\n",
    "    y_true=all_labels,\n",
    "    y_pred=all_predictions,\n",
    "    class_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot classification metrics (ROC curve, precision-recall curve)\n",
    "plot_classification_metrics(\n",
    "    y_true=all_labels,\n",
    "    y_pred=all_predictions,\n",
    "    y_proba=np.array(all_probas),\n",
    "    class_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample texts for prediction\n",
    "sample_texts = [\n",
    "    \"This movie was fantastic! The acting was superb and the plot kept me engaged throughout.\",\n",
    "    \"I really enjoyed this film. Great performances by the cast.\",\n",
    "    \"What a waste of time. The story made no sense and the special effects were terrible.\",\n",
    "    \"This is one of the worst movies I've ever seen. Boring and predictable.\",\n",
    "    \"The movie was just okay. Some good moments but overall pretty average.\"\n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict(sample_texts)\n",
    "probabilities = classifier.predict_proba(sample_texts)\n",
    "\n",
    "# Display results\n",
    "print(\"Prediction Results:\")\n",
    "for i, (text, pred, proba) in enumerate(zip(sample_texts, predictions, probabilities)):\n",
    "    sentiment = class_names[pred]\n",
    "    confidence = proba[pred] * 100\n",
    "    print(f\"\\nText {i+1}: {text[:50]}...\")\n",
    "    print(f\"Prediction: {sentiment} (Confidence: {confidence:.2f}%)\")\n",
    "    print(f\"Class probabilities: Negative={proba[0]:.4f}, Positive={proba[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model\n",
    "save_path = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "classifier.save(save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the model\n",
    "loaded_classifier = TransformerClassifier.load(save_path)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Verify with a prediction\n",
    "test_text = \"I absolutely loved this movie, would watch it again!\"\n",
    "pred = loaded_classifier.predict([test_text])[0]\n",
    "print(f\"Test prediction: {class_names[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the text classification capabilities of the NLP toolkit:\n",
    "\n",
    "1. We loaded and preprocessed the IMDB dataset for sentiment analysis\n",
    "2. We trained a DistilBERT classifier on the dataset\n",
    "3. We evaluated model performance and visualized the results\n",
    "4. We made predictions on new text samples\n",
    "5. We saved and loaded the model for future use\n",
    "\n",
    "The model achieved good performance even with limited training time, demonstrating the effectiveness of transformer models for text classification tasks. For production use, consider training for more epochs and trying different model architectures or hyperparameters to optimize performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
