{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Demo (Robust Version)\n",
    "\n",
    "This notebook demonstrates the text classification capabilities of the NLP toolkit, with special handling to ensure compatibility with different dataset structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup path to allow importing from the src directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import toolkit modules\n",
    "from src.data.preprocessing import TextPreprocessor\n",
    "from src.data.data_loader import get_text_classification_loader\n",
    "from src.models.classifier import TransformerClassifier\n",
    "from src.training.metrics import classification_report\n",
    "from src.utils.visualization import plot_confusion_matrix, plot_classification_metrics, plot_training_history\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "TASK = \"classification\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"  # Smaller model for faster execution\n",
    "DATASET_NAME = \"imdb\"  # Movie reviews sentiment dataset\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1  # Using just 1 epoch for demonstration purposes\n",
    "\n",
    "# Output directory for model and results\n",
    "OUTPUT_DIR = os.path.join(project_root, \"models\", \"demo_classifier\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset directly using Hugging Face datasets library\n",
    "print(f\"Loading dataset: {DATASET_NAME}\")\n",
    "hf_dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Dataset splits: {list(hf_dataset.keys())}\")\n",
    "for split in hf_dataset.keys():\n",
    "    print(f\"  {split}: {len(hf_dataset[split])} examples\")\n",
    "\n",
    "# Analyze the structure of the dataset examples\n",
    "print(\"\\nAnalyzing dataset structure:\")\n",
    "try:\n",
    "    # Try to get the first example\n",
    "    example = hf_dataset[\"train\"][0]\n",
    "    print(f\"Example type: {type(example)}\")\n",
    "    \n",
    "    # Check if it's a dictionary\n",
    "    if isinstance(example, dict):\n",
    "        print(f\"Example fields: {list(example.keys())}\")\n",
    "        \n",
    "        # Safely show text field\n",
    "        if 'text' in example:\n",
    "            text = example.get('text', example.get('sentence', str(example)))\n",
    "            print(f\"Text field type: {type(text)}\")\n",
    "            if isinstance(text, str):\n",
    "                print(f\"Text preview: {text[:50]}...\")\n",
    "        else:\n",
    "            print(\"No 'text' field found\")\n",
    "            \n",
    "        # Safely show label field\n",
    "        if 'label' in example:\n",
    "            print(f\"Label: {example.get('label', 0)} (type: {type(example.get('label', 0))})\")\n",
    "    else:\n",
    "        # If not a dictionary, try to interpret it as raw text\n",
    "        print(f\"Example might be raw text. First 50 chars: {str(example)[:50]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing dataset: {type(e).__name__}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a custom wrapper for dataset access that handles different structures\n",
    "class RobustDatasetWrapper:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        # Handle split access\n",
    "        if isinstance(key, str) and key in self.dataset:\n",
    "            # Return a wrapped split\n",
    "            return RobustSplitWrapper(self.dataset[key])\n",
    "        return self.dataset[key]\n",
    "    \n",
    "    def keys(self):\n",
    "        return self.dataset.keys()\n",
    "        \n",
    "class RobustSplitWrapper:\n",
    "    def __init__(self, split):\n",
    "        self.split = split\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Get item from the original split\n",
    "        item = self.split[idx]\n",
    "        \n",
    "        # Handle different item structures\n",
    "        if isinstance(item, dict):\n",
    "            # Dictionary - look for text and label\n",
    "            return {\n",
    "                'text': item.get('text', str(item)),\n",
    "                'label': item.get('label', 0)\n",
    "            }\n",
    "        elif isinstance(item, str):\n",
    "            # String - treat as text\n",
    "            return {'text': item, 'label': 0}\n",
    "        else:\n",
    "            # Something else - convert to string\n",
    "            return {'text': str(item), 'label': 0}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.split)\n",
    "    \n",
    "    def select(self, indices):\n",
    "        # Handle select method (used by DataLoader)\n",
    "        return RobustSplitWrapper(self.split.select(indices))\n",
    "\n",
    "# Wrap the dataset\n",
    "robust_dataset = RobustDatasetWrapper(hf_dataset)\n",
    "\n",
    "# Test the wrapped dataset\n",
    "print(\"\\nTesting robust dataset wrapper:\")\n",
    "print(f\"Splits: {list(robust_dataset.keys())}\")\n",
    "\n",
    "# Show example data with the wrapper\n",
    "print(\"\\nExample data with wrapper:\")\n",
    "for i in range(3):\n",
    "    example = robust_dataset[\"train\"][i]\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Text: {example.get('text', example.get('sentence', str(example)))[:50]}...\")\n",
    "    print(f\"  Label: {example.get('label', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a custom PyTorch Dataset for training\n",
    "class CustomTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_split, tokenizer, max_length=128):\n",
    "        self.dataset = dataset_split\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get item from wrapped dataset\n",
    "        item = self.dataset[idx]\n",
    "        text = item['text']\n",
    "        label = item['label']\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        # Add the label\n",
    "        encoding['labels'] = torch.tensor(label)\n",
    "        \n",
    "        return encoding\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomTextDataset(robust_dataset[\"train\"], tokenizer, MAX_LENGTH)\n",
    "test_dataset = CustomTextDataset(robust_dataset[\"test\"], tokenizer, MAX_LENGTH)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create a dict of dataloaders for compatibility with existing code\n",
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"test\": test_dataloader\n",
    "}\n",
    "\n",
    "print(\"DataLoaders created:\")\n",
    "for split, dataloader in dataloaders.items():\n",
    "    print(f\"  {split}: {len(dataloader)} batches of size {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the classifier\n",
    "classifier = TransformerClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_labels=2,  # Binary classification for sentiment\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "# Display model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Task: {TASK}\")\n",
    "print(f\"Number of parameters: {classifier.get_model_size():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "training_history = classifier.train(\n",
    "    train_dataloader=dataloaders[\"train\"],\n",
    "    val_dataloader=dataloaders[\"test\"],\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plot_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "test_results = classifier.evaluate(dataloaders[\"test\"])\n",
    "\n",
    "# Display results\n",
    "print(\"Test Results:\")\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate predictions and true labels\n",
    "predictions, true_labels = classifier.predict(dataloaders[\"test\"])\n",
    "\n",
    "# Calculate and display classification report\n",
    "report = classification_report(true_labels, predictions, target_names=[\"Negative\", \"Positive\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(true_labels, predictions, class_names=[\"Negative\", \"Positive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample reviews for prediction\n",
    "sample_reviews = [\n",
    "    \"This movie was fantastic! The acting was great and the plot was engaging.\",\n",
    "    \"I was disappointed with this film. The story was predictable and the characters were one-dimensional.\",\n",
    "    \"A decent movie, but nothing special. Some parts were good, others were mediocre.\"\n",
    "]\n",
    "\n",
    "# Preprocess the reviews\n",
    "preprocessed_reviews = [preprocessor.preprocess_text(review) for review in sample_reviews]\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict_text(preprocessed_reviews)\n",
    "\n",
    "# Map predictions to sentiment labels\n",
    "sentiment_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Prediction Results:\")\n",
    "for i, (review, prediction) in enumerate(zip(sample_reviews, predictions)):\n",
    "    print(f\"\\nReview {i+1}: {review[:100]}...\")\n",
    "    print(f\"Prediction: {sentiment_labels[prediction]} (class {prediction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model and config\n",
    "save_path = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "classifier.save(save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the model\n",
    "loaded_classifier = TransformerClassifier.load(save_path)\n",
    "print(f\"Model loaded from {save_path}\")\n",
    "\n",
    "# Verify loaded model works\n",
    "loaded_predictions = loaded_classifier.predict_text(preprocessed_reviews)\n",
    "\n",
    "# Check if predictions match\n",
    "match = all(p1 == p2 for p1, p2 in zip(predictions, loaded_predictions))\n",
    "print(f\"Loaded model predictions match original: {match}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}