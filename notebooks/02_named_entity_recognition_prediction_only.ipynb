{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) Demo\n",
    "\n",
    "This notebook demonstrates the Named Entity Recognition capabilities of the NLP toolkit, including:\n",
    "- Loading and preprocessing data for NER\n",
    "- Using pre-trained NER models\n",
    "- Fine-tuning on custom datasets\n",
    "- Evaluating NER performance\n",
    "- Visualizing entity predictions\n",
    "- Applying NER to real-world text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup path to allow importing from the src directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import toolkit modules\n",
    "from src.data.preprocessing import TextPreprocessor\n",
    "from src.data.data_loader import get_ner_loader\n",
    "from src.models.named_entity_recognition import NERModel\n",
    "from src.training.metrics import token_classification_metrics\n",
    "from src.utils.visualization import plot_token_classification_results\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "TASK = \"ner\"\n",
    "MODEL_NAME = \"dslim/bert-base-NER\"  # Pre-trained NER model\n",
    "DATASET_NAME = \"conll2003\"  # Standard NER benchmark dataset\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1  # Using just 1 epoch for demonstration purposes\n",
    "\n",
    "# Output directory for model and results\n",
    "OUTPUT_DIR = os.path.join(project_root, \"models\", \"demo_ner\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring NER with Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize a pre-trained NER model\n",
    "ner_model = NERModel(model_name=MODEL_NAME)\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Label map: {ner_model.id2label}\")\n",
    "print(f\"Number of entity types: {len(set([label.split('-')[1] for label in ner_model.id2label.values() if label != 'O']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample texts for NER prediction\n",
    "sample_texts = [\n",
    "    \"Apple Inc. is planning to open a new store in New York City next month.\",\n",
    "    \"The European Union and United States signed a new trade agreement yesterday in Brussels.\",\n",
    "    \"Albert Einstein developed the theory of relativity while working at the Swiss Patent Office in Bern.\",\n",
    "    \"Microsoft CEO Satya Nadella announced a partnership with OpenAI to develop new AI technologies.\"\n",
    "]\n",
    "\n",
    "# Perform NER on sample texts\n",
    "predictions = ner_model.predict(sample_texts)\n",
    "\n",
    "# Display results\n",
    "for i, (text, entities) in enumerate(zip(sample_texts, predictions)):\n",
    "    print(f\"\\nText {i+1}: {text}\")\n",
    "    print(\"Entities:\")\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        print(f\"  {entity_text} ({entity['entity']}): {entity['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Prediction-Only Version\n\n",
    "This is a simplified version of the NER demo notebook that focuses on prediction rather than training.",
    "It demonstrates how to use pre-trained NER models for inference, but skips the training sections",
    "which require specific dataset formatting and tensor shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-trained NER Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize a pre-trained NER model\n",
    "ner_model = NERModel(model_name=MODEL_NAME)\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Label map: {ner_model.id2label}\")\n",
    "print(f\"Number of entity types: {len(set([label.split('-')[1] for label in ner_model.id2label.values() if label != 'O']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample texts for NER prediction\n",
    "sample_texts = [\n",
    "    \"Apple Inc. is planning to open a new store in New York City next month.\",\n",
    "    \"The European Union and United States signed a new trade agreement yesterday in Brussels.\",\n",
    "    \"Albert Einstein developed the theory of relativity while working at the Swiss Patent Office in Bern.\",\n",
    "    \"Microsoft CEO Satya Nadella announced a partnership with OpenAI to develop new AI technologies.\"\n",
    "]\n",
    "\n",
    "# Perform NER on sample texts\n",
    "predictions = ner_model.predict(sample_texts)\n",
    "\n",
    "# Display results\n",
    "for i, (text, entities) in enumerate(zip(sample_texts, predictions)):\n",
    "    print(f\"\\nText {i+1}: {text}\")\n",
    "    print(\"Entities:\")\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        print(f\"  {entity_text} ({entity['entity']}): {entity['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize NER predictions for the first text\n",
    "def visualize_ner_prediction(text, entities):\n",
    "    \"\"\"Create word-level visualization of NER results.\"\"\"\n",
    "    tokens = text.split()\n",
    "    token_entities = ['O'] * len(tokens)\n",
    "    \n",
    "    # Assign entity tags to tokens (simplified approach)\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        entity_type = entity['entity'].split('-')[1] if '-' in entity['entity'] else entity['entity']\n",
    "        \n",
    "        # Find the token(s) that match this entity\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in entity_text or entity_text in token:\n",
    "                prefix = 'B-' if i == 0 or token_entities[i-1] == 'O' else 'I-'\n",
    "                token_entities[i] = f\"{prefix}{entity_type}\"\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_token_classification_results(\n",
    "        tokens=tokens,\n",
    "        true_labels=None,  # We don't have ground truth here\n",
    "        pred_labels=token_entities\n",
    "    )\n",
    "\n",
    "# Visualize the first example\n",
    "visualize_ner_prediction(sample_texts[0], predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize NER predictions for the first text\n",
    "def visualize_ner_prediction(text, entities):\n",
    "    \"\"\"Create word-level visualization of NER results.\"\"\"\n",
    "    tokens = text.split()\n",
    "    token_entities = ['O'] * len(tokens)\n",
    "    \n",
    "    # Assign entity tags to tokens (simplified approach)\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        entity_type = entity['entity'].split('-')[1] if '-' in entity['entity'] else entity['entity']\n",
    "        \n",
    "        # Find the token(s) that match this entity\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in entity_text or entity_text in token:\n",
    "                prefix = 'B-' if i == 0 or token_entities[i-1] == 'O' else 'I-'\n",
    "                token_entities[i] = f\"{prefix}{entity_type}\"\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_token_classification_results(\n",
    "        tokens=tokens,\n",
    "        true_labels=None,  # We don't have ground truth here\n",
    "        pred_labels=token_entities\n",
    "    )\n",
    "\n",
    "# Visualize the first example\n",
    "visualize_ner_prediction(sample_texts[0], predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Examples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Try with your own custom text examples\n",
    "custom_texts = [\n",
    "    \"Google and Facebook announced new AI research partnerships at Stanford University yesterday.\",\n",
    "    \"Tesla CEO Elon Musk visited their Berlin Gigafactory in Germany last month.\",\n",
    "    \"The World Health Organization released new guidelines for COVID-19 prevention in New York.\"\n",
    "]\n",
    "\n",
    "# Run predictions\n",
    "custom_predictions = ner_model.predict(custom_texts)\n",
    "\n",
    "# Display results\n",
    "for i, (text, entities) in enumerate(zip(custom_texts, custom_predictions)):\n",
    "    print(f\"\\nText {i+1}: {text}\")\n",
    "    print(\"Entities:\")\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        entity_type = entity['entity'].replace('B-', '').replace('I-', '') if '-' in entity['entity'] else entity['entity']\n",
    "        print(f\"  {entity_text} ({entity_type}): {entity['score']:.3f}\")\n",
    "\n",
    "# Visualize the first custom example\n",
    "visualize_ner_prediction(custom_texts[0], custom_predictions[0])"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}