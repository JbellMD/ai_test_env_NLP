{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Demo\n",
    "\n",
    "This notebook demonstrates the text classification capabilities of the NLP toolkit, including:\n",
    "- Loading and preprocessing data\n",
    "- Training a transformer-based classifier\n",
    "- Evaluating model performance\n",
    "- Visualizing results\n",
    "- Making predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup path to allow importing from the src directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import toolkit modules\n",
    "from src.data.preprocessing import TextPreprocessor\n",
    "from src.data.data_loader import get_text_classification_loader\n",
    "from src.models.classifier import TransformerClassifier\n",
    "from src.training.metrics import classification_report\n",
    "from src.utils.visualization import plot_confusion_matrix, plot_classification_metrics, plot_training_history\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "TASK = \"classification\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"  # Smaller model for faster execution\n",
    "DATASET_NAME = \"imdb\"  # Movie reviews sentiment dataset\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1  # Using just 1 epoch for demonstration purposes\n",
    "\n",
    "# Output directory for model and results\n",
    "OUTPUT_DIR = os.path.join(project_root, \"models\", \"demo_classifier\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Create dataset loader\n",
    "dataset_loader = get_text_classification_loader(\n",
    "    tokenizer=tokenizer,\n",
    "    preprocessor=preprocessor,\n",
    "    max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset directly using Hugging Face datasets\n",
    "# This approach ensures we get the expected structure\n",
    "raw_dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Number of splits: {len(raw_dataset.keys())}\")\n",
    "for split in raw_dataset.keys():\n",
    "    print(f\"  {split}: {len(raw_dataset[split])} examples\")\n",
    "\n",
    "# Show example data\n",
    "print(\"\\nExample data:\")\n",
    "for i, example in enumerate(raw_dataset[\"train\"][:3]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Text: {example['text'][:100]}...\")\n",
    "    print(f\"  Label: {example['label']}\")\n",
    "\n",
    "# We still use our loader to create PyTorch datasets\n",
    "dataset = raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create PyTorch DataLoaders for training and evaluation\n",
    "dataloaders = dataset_loader.create_dataloaders(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_train=True\n",
    ")\n",
    "\n",
    "print(\"DataLoaders created:\")\n",
    "for split, dataloader in dataloaders.items():\n",
    "    print(f\"  {split}: {len(dataloader)} batches of size {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the classifier\n",
    "classifier = TransformerClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_labels=2,  # Binary classification for sentiment\n",
    "    task=\"binary\"\n",
    ")\n",
    "\n",
    "# Display model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Task: {TASK}\")\n",
    "print(f\"Number of parameters: {classifier.get_model_size():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "training_history = classifier.train(\n",
    "    train_dataloader=dataloaders[\"train\"],\n",
    "    val_dataloader=dataloaders[\"test\"],\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plot_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "test_results = classifier.evaluate(dataloaders[\"test\"])\n",
    "\n",
    "# Display results\n",
    "print(\"Test Results:\")\n",
    "for metric, value in test_results.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate predictions and true labels\n",
    "predictions, true_labels = classifier.predict(dataloaders[\"test\"])\n",
    "\n",
    "# Calculate and display classification report\n",
    "report = classification_report(true_labels, predictions, target_names=[\"Negative\", \"Positive\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(true_labels, predictions, class_names=[\"Negative\", \"Positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot classification metrics\n",
    "plot_classification_metrics(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample reviews for prediction\n",
    "sample_reviews = [\n",
    "    \"This movie was fantastic! The acting was great and the plot was engaging.\",\n",
    "    \"I was disappointed with this film. The story was predictable and the characters were one-dimensional.\",\n",
    "    \"A decent movie, but nothing special. Some parts were good, others were mediocre.\"\n",
    "]\n",
    "\n",
    "# Preprocess the reviews\n",
    "preprocessed_reviews = [preprocessor.preprocess_text(review) for review in sample_reviews]\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict_text(preprocessed_reviews)\n",
    "\n",
    "# Map predictions to sentiment labels\n",
    "sentiment_labels = [\"Negative\", \"Positive\"]\n",
    "\n",
    "# Display results\n",
    "print(\"Prediction Results:\")\n",
    "for i, (review, prediction) in enumerate(zip(sample_reviews, predictions)):\n",
    "    print(f\"\\nReview {i+1}: {review[:100]}...\")\n",
    "    print(f\"Prediction: {sentiment_labels[prediction]} (class {prediction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model and config\n",
    "save_path = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "classifier.save(save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the model\n",
    "loaded_classifier = TransformerClassifier.load(save_path)\n",
    "print(f\"Model loaded from {save_path}\")\n",
    "\n",
    "# Verify loaded model works\n",
    "loaded_predictions = loaded_classifier.predict_text(preprocessed_reviews)\n",
    "\n",
    "# Check if predictions match\n",
    "match = all(p1 == p2 for p1, p2 in zip(predictions, loaded_predictions))\n",
    "print(f\"Loaded model predictions match original: {match}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
