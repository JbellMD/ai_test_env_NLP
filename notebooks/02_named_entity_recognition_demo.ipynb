{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) Demo\n",
    "\n",
    "This notebook demonstrates the Named Entity Recognition capabilities of the NLP toolkit, including:\n",
    "- Loading and preprocessing data for NER\n",
    "- Using pre-trained NER models\n",
    "- Fine-tuning on custom datasets\n",
    "- Evaluating NER performance\n",
    "- Visualizing entity predictions\n",
    "- Applying NER to real-world text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup path to allow importing from the src directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import toolkit modules\n",
    "from src.data.preprocessing import TextPreprocessor\n",
    "from src.data.data_loader import get_ner_loader\n",
    "from src.models.named_entity_recognition import NERModel\n",
    "from src.training.metrics import token_classification_metrics\n",
    "from src.utils.visualization import plot_token_classification_results\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "TASK = \"ner\"\n",
    "MODEL_NAME = \"dslim/bert-base-NER\"  # Pre-trained NER model\n",
    "DATASET_NAME = \"conll2003\"  # Standard NER benchmark dataset\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1  # Using just 1 epoch for demonstration purposes\n",
    "\n",
    "# Output directory for model and results\n",
    "OUTPUT_DIR = os.path.join(project_root, \"models\", \"demo_ner\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring NER with Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize a pre-trained NER model\n",
    "ner_model = NERModel(model_name=MODEL_NAME)\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Label map: {ner_model.id2label}\")\n",
    "print(f\"Number of entity types: {len(set([label.split('-')[1] for label in ner_model.id2label.values() if label != 'O']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample texts for NER prediction\n",
    "sample_texts = [\n",
    "    \"Apple Inc. is planning to open a new store in New York City next month.\",\n",
    "    \"The European Union and United States signed a new trade agreement yesterday in Brussels.\",\n",
    "    \"Albert Einstein developed the theory of relativity while working at the Swiss Patent Office in Bern.\",\n",
    "    \"Microsoft CEO Satya Nadella announced a partnership with OpenAI to develop new AI technologies.\"\n",
    "]\n",
    "\n",
    "# Perform NER on sample texts\n",
    "predictions = ner_model.predict(sample_texts)\n",
    "\n",
    "# Display results\n",
    "for i, (text, entities) in enumerate(zip(sample_texts, predictions)):\n",
    "    print(f\"\\nText {i+1}: {text}\")\n",
    "    print(\"Entities:\")\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        print(f\"  {entity_text} ({entity['entity']}): {entity['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize NER predictions for the first text\n",
    "def visualize_ner_prediction(text, entities):\n",
    "    \"\"\"Create word-level visualization of NER results.\"\"\"\n",
    "    tokens = text.split()\n",
    "    token_entities = ['O'] * len(tokens)\n",
    "    \n",
    "    # Assign entity tags to tokens (simplified approach)\n",
    "    for entity in entities:\n",
    "        entity_text = text[entity['start']:entity['end']]\n",
    "        entity_type = entity['entity'].split('-')[1] if '-' in entity['entity'] else entity['entity']\n",
    "        \n",
    "        # Find the token(s) that match this entity\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in entity_text or entity_text in token:\n",
    "                prefix = 'B-' if i == 0 or token_entities[i-1] == 'O' else 'I-'\n",
    "                token_entities[i] = f\"{prefix}{entity_type}\"\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_token_classification_results(\n",
    "        tokens=tokens,\n",
    "        true_labels=None,  # We don't have ground truth here\n",
    "        pred_labels=token_entities\n",
    "    )\n",
    "\n",
    "# Visualize the first example\n",
    "visualize_ner_prediction(sample_texts[0], predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Create dataset loader\n",
    "dataset_loader = get_ner_loader(\n",
    "    tokenizer=tokenizer,\n",
    "    preprocessor=preprocessor,\n",
    "    max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the ConLL-2003 dataset\n",
    "dataset = dataset_loader.load_huggingface_dataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    text_column=\"tokens\",\n",
    "    label_column=\"ner_tags\"\n",
    ")\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Number of splits: {len(dataset.keys())}\")\n",
    "for split in dataset.keys():\n",
    "    print(f\"  {split}: {len(dataset[split])} examples\")\n",
    "\n",
    "# Show example data\n",
    "print(\"\\nExample data:\")\n",
    "for i, example in enumerate(dataset[\"train\"][:2]):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  Tokens: {example['tokens'][:10]}...\")\n",
    "    print(f\"  NER tags: {example['ner_tags'][:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get the label mapping from the dataset\n",
    "from datasets import ClassLabel\n",
    "\n",
    "# Extract the label names if available\n",
    "if isinstance(dataset['train'].features['ner_tags'].feature, ClassLabel):\n",
    "    label_names = dataset['train'].features['ner_tags'].feature.names\n",
    "    print(\"NER Labels:\")\n",
    "    for i, name in enumerate(label_names):\n",
    "        print(f\"  {i}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocess the dataset\n",
    "preprocessed_dataset = dataset_loader.preprocess_dataset(dataset)\n",
    "\n",
    "# Create PyTorch DataLoaders\n",
    "dataloaders = dataset_loader.create_torch_dataloaders(\n",
    "    preprocessed_dataset,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Extract train and validation dataloaders\n",
    "train_dataloader = dataloaders[\"train\"]\n",
    "val_dataloader = dataloaders[\"validation\"]\n",
    "\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize NER model for fine-tuning\n",
    "ner_model = NERModel(\n",
    "    model_name=MODEL_NAME,\n",
    "    num_labels=len(label_names) if 'label_names' in locals() else None\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Number of parameters: {ner_model.get_model_size():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model (only for demonstration - typically needs more epochs)\n",
    "training_history = ner_model.train(\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_best=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "eval_results = ner_model.evaluate(val_dataloader)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(f\"  Loss: {eval_results['loss']:.4f}\")\n",
    "print(f\"  F1 Score: {eval_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {eval_results['precision']:.4f}\")\n",
    "print(f\"  Recall: {eval_results['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute detailed per-entity metrics\n",
    "if 'label_names' in locals():\n",
    "    # Collect predictions and true labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_valid_indices = []\n",
    "    \n",
    "    device = ner_model.device\n",
    "    model = ner_model.model\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=2).cpu().numpy()\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            \n",
    "            # Filter out padding tokens (-100)\n",
    "            for i in range(labels.shape[0]):\n",
    "                valid_indices = labels[i] != -100\n",
    "                all_predictions.extend(predictions[i, valid_indices].tolist())\n",
    "                all_labels.extend(labels[i, valid_indices].tolist())\n",
    "    \n",
    "    # Convert numeric labels to names\n",
    "    pred_labels = [label_names[p] for p in all_predictions]\n",
    "    true_labels = [label_names[t] for t in all_labels]\n",
    "    \n",
    "    # Calculate per-entity metrics\n",
    "    entity_types = sorted(set([name.split('-')[1] for name in label_names if name != 'O']))\n",
    "    \n",
    "    print(\"\\nPer-Entity Type Metrics:\")\n",
    "    for entity_type in entity_types:\n",
    "        # Filter for just this entity type\n",
    "        entity_preds = ['1' if (p.startswith('B-') or p.startswith('I-')) and p.endswith(entity_type) else '0' for p in pred_labels]\n",
    "        entity_trues = ['1' if (t.startswith('B-') or t.startswith('I-')) and t.endswith(entity_type) else '0' for t in true_labels]\n",
    "        \n",
    "        # Calculate basic metrics\n",
    "        correct = sum(1 for p, t in zip(entity_preds, entity_trues) if p == '1' and t == '1')\n",
    "        total_pred = sum(1 for p in entity_preds if p == '1')\n",
    "        total_true = sum(1 for t in entity_trues if t == '1')\n",
    "        \n",
    "        precision = correct / total_pred if total_pred > 0 else 0\n",
    "        recall = correct / total_true if total_true > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"  {entity_type}:\")\n",
    "        print(f\"    Precision: {precision:.4f}\")\n",
    "        print(f\"    Recall: {recall:.4f}\")\n",
    "        print(f\"    F1: {f1:.4f}\")\n",
    "        print(f\"    Support: {total_true}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing NER Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get a batch of examples from validation set\n",
    "batch = next(iter(val_dataloader))\n",
    "input_ids = batch[\"input_ids\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "labels = batch[\"labels\"]\n",
    "\n",
    "# Select one example\n",
    "example_idx = 0\n",
    "example_input_ids = input_ids[example_idx].unsqueeze(0).to(ner_model.device)\n",
    "example_attention_mask = attention_mask[example_idx].unsqueeze(0).to(ner_model.device)\n",
    "example_labels = labels[example_idx]\n",
    "\n",
    "# Get predictions\n",
    "ner_model.model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = ner_model.model(input_ids=example_input_ids, attention_mask=example_attention_mask)\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)[0].cpu().numpy()\n",
    "\n",
    "# Convert ids to tokens and labels\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[example_idx])\n",
    "valid_indices = example_labels != -100\n",
    "\n",
    "valid_tokens = [tokens[i] for i in range(len(tokens)) if valid_indices[i]]\n",
    "valid_true_labels = [label_names[example_labels[i]] for i in range(len(example_labels)) if valid_indices[i]]\n",
    "valid_pred_labels = [label_names[predictions[i]] for i in range(len(predictions)) if valid_indices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Print tokens and their predicted/true labels\n",
    "print(\"Token\\tTrue Label\\tPredicted Label\")\n",
    "print(\"-\" * 50)\n",
    "for token, true_label, pred_label in zip(valid_tokens, valid_true_labels, valid_pred_labels):\n",
    "    print(f\"{token}\\t{true_label}\\t{pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize using our utility function\n",
    "plot_token_classification_results(\n",
    "    tokens=valid_tokens,\n",
    "    true_labels=valid_true_labels,\n",
    "    pred_labels=valid_pred_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Applying NER to Real-world Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Real-world example text\n",
    "news_article = \"\"\"\n",
    "Apple Inc. announced today that CEO Tim Cook will present the latest iPhone model at their headquarters in Cupertino, California next month. \n",
    "The event, scheduled for September 12th, is expected to draw technology journalists from around the world including representatives from the New York Times and CNN.\n",
    "Financial analysts from Goldman Sachs and JP Morgan Chase predict the new device will boost Apple's stock price on NASDAQ.\n",
    "Meanwhile, competitors Samsung and Google are reportedly preparing their own product announcements in response.\n",
    "\"\"\"\n",
    "\n",
    "# Apply NER to the text\n",
    "entities = ner_model.predict([news_article])[0]\n",
    "\n",
    "# Display entities by type\n",
    "entity_by_type = {}\n",
    "for entity in entities:\n",
    "    entity_type = entity['entity'].split('-')[1] if '-' in entity['entity'] else entity['entity']\n",
    "    entity_text = news_article[entity['start']:entity['end']]\n",
    "    \n",
    "    if entity_type not in entity_by_type:\n",
    "        entity_by_type[entity_type] = []\n",
    "    entity_by_type[entity_type].append(entity_text)\n",
    "\n",
    "print(\"Entities by Type:\")\n",
    "for entity_type, entities in entity_by_type.items():\n",
    "    print(f\"\\n{entity_type}:\")\n",
    "    for entity in sorted(set(entities)):\n",
    "        print(f\"  {entity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize entities in the text\n",
    "from IPython.display import HTML, display\n",
    "import re\n",
    "\n",
    "def highlight_entities(text, entities):\n",
    "    \"\"\"Highlight entities in text with HTML colors.\"\"\"\n",
    "    # Define colors for different entity types\n",
    "    colors = {\n",
    "        'PER': '#FFADAD',  # Light red\n",
    "        'ORG': '#FFD6A5',  # Light orange\n",
    "        'LOC': '#CAFFBF',  # Light green\n",
    "        'MISC': '#9BF6FF',  # Light blue\n",
    "    }\n",
    "    \n",
    "    # Sort entities by start position in reverse (to avoid index shifts)\n",
    "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
    "    \n",
    "    # Insert HTML tags for highlighting\n",
    "    result = text\n",
    "    for entity in sorted_entities:\n",
    "        entity_type = entity['entity'].split('-')[1] if '-' in entity['entity'] else entity['entity']\n",
    "        color = colors.get(entity_type, '#E2E2E2')  # Default gray for unknown types\n",
    "        \n",
    "        start, end = entity['start'], entity['end']\n",
    "        entity_html = f'<span style=\"background-color: {color}; padding: 2px; border-radius: 3px;\" title=\"{entity_type}\">{text[start:end]}</span>'\n",
    "        \n",
    "        result = result[:start] + entity_html + result[end:]\n",
    "    \n",
    "    # Replace newlines with HTML breaks\n",
    "    result = result.replace('\\n', '<br>')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Display highlighted text\n",
    "html_result = highlight_entities(news_article, entities)\n",
    "display(HTML(f'<div style=\"font-size: 14px; line-height: 1.5;\">{html_result}</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model\n",
    "save_path = os.path.join(OUTPUT_DIR, \"final_model\")\n",
    "ner_model.save(save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the model\n",
    "loaded_model = NERModel.load(save_path)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Verify with a prediction\n",
    "test_text = \"Bill Gates founded Microsoft in 1975.\"\n",
    "entities = loaded_model.predict([test_text])[0]\n",
    "\n",
    "print(\"Detected entities:\")\n",
    "for entity in entities:\n",
    "    entity_text = test_text[entity['start']:entity['end']]\n",
    "    print(f\"  {entity_text} ({entity['entity']}): {entity['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the Named Entity Recognition capabilities of the NLP toolkit:\n",
    "\n",
    "1. We explored pre-trained NER models and their predictions\n",
    "2. We loaded and preprocessed the CoNLL-2003 dataset for NER fine-tuning\n",
    "3. We fine-tuned a BERT-based NER model on the dataset\n",
    "4. We evaluated model performance with detailed metrics by entity type\n",
    "5. We visualized NER predictions on real-world text\n",
    "6. We saved and loaded the model for future use\n",
    "\n",
    "NER is useful for many downstream applications including information extraction, knowledge graph construction, and content recommendation. The model provides a solid foundation for these applications, though for production use you would typically train for more epochs and potentially on domain-specific data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
